{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeto apresentado à disciplina de Introdução a multimidia, como requisito parcial para a obtenção da aprovação.\n",
    "#### Autores: Adriano Santana, Bruno, Jefferson Costa, Matheus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando as dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino = pd.read_csv('./data/dataset_treino') ### Importando nosso dataframe de treino\n",
    "df_treino.drop('Unnamed: 0', axis=1, inplace=True) ### Removendo coluna Unnamed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando nosso dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./scripts') ### Importando a função clean text dentro da pasta script\n",
    "from cleanText import cleanTxt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Removendo @mentions, '#' hash tag, RT, hyperlink "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino['tweet'] = df_treino['tweet'].apply(cleanTxt) ### A coluna tweet recebe agora os tweets limpos\n",
    "df_treino['tweet'] = df_treino['tweet'].apply(lambda x: x.lower()) ### Colocando todos os tweets em lowerCase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Removendo pontuações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./scripts') ### Importando a função removePunctuation\n",
    "from removePunctuation import removePunctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino['tweet'] = df_treino.loc[:,'tweet'].apply(removePunctuation) ### Remove pontuações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removendo as stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./scripts') ### Importando a função removePunctuation\n",
    "from removeStopWords import removeStopWords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino['tweet'] = df_treino.loc[:,'tweet'].apply(removeStopWords) ### Remove stopwords com base na língua portuguesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./scripts') ### Importando a função removePunctuation\n",
    "from tokenizar import Tokenizar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_tokenizados = df_treino.loc[:,'tweet'].apply(Tokenizar) ### Criar um array de tokens a partir dos tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\n",
    "\n",
    "If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "tweets_vector = vectorizer.fit_transform(df_treino['tweet'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino de modelo de Machine Learning:\n",
    "modelo = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando dataframe em treino e teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(tweets_vector, df_treino['Analise'], test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "modelo.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negativo', 'Negativo', 'Negativo', 'Negativo', 'Neutro',\n",
       "       'Positivo', 'Neutro', 'Negativo', 'Neutro', 'Negativo', 'Neutro',\n",
       "       'Negativo', 'Neutro', 'Negativo', 'Neutro', 'Positivo', 'Neutro',\n",
       "       'Neutro', 'Negativo', 'Positivo', 'Positivo', 'Negativo', 'Neutro',\n",
       "       'Positivo', 'Neutro', 'Neutro', 'Neutro', 'Positivo', 'Negativo',\n",
       "       'Negativo', 'Neutro', 'Neutro', 'Negativo', 'Neutro', 'Neutro',\n",
       "       'Negativo', 'Neutro', 'Neutro', 'Negativo', 'Neutro', 'Neutro',\n",
       "       'Negativo', 'Neutro', 'Neutro', 'Neutro'], dtype='<U8')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.80      0.75      0.77        16\n",
      "      Neutro       0.83      0.87      0.85        23\n",
      "    Positivo       0.50      0.50      0.50         6\n",
      "\n",
      "    accuracy                           0.78        45\n",
      "   macro avg       0.71      0.71      0.71        45\n",
      "weighted avg       0.78      0.78      0.78        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(modelo.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificando dataframe primeiro turno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primeiro_turno = pd.read_csv('./data/df_primeiro_turno_original') # Lendo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_original = df_primeiro_turno[['tweet','palavra_chave']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primeiro_turno.drop('Unnamed: 0', axis=1, inplace=True) # Removida coluna unnamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primeiro_turno['tweet'] = df_primeiro_turno['tweet'].apply(cleanTxt) ### A coluna tweet recebe agora os tweets limpos\n",
    "df_primeiro_turno['tweet'] = df_primeiro_turno['tweet'].apply(lambda x: x.lower()) ### Colocando todos os tweets em lowerCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primeiro_turno['tweet'] = df_primeiro_turno.loc[:,'tweet'].apply(removePunctuation) ### Remove pontuações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primeiro_turno['tweet'] = df_primeiro_turno.loc[:,'tweet'].apply(removeStopWords) ### Remove stopwords com base na língua portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_primeiro_turno = vectorizer.transform(df_primeiro_turno['tweet'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x1006 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 23435 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_primeiro_turno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacao_primeiro_turno = modelo.predict(tweets_primeiro_turno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Neutro', 'Neutro'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificacao_primeiro_turno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moda: Neutro\n",
      "Positivos: 26.67 %\n",
      "Neutros: 51.11 %\n",
      "Negativos: 22.22 %\n"
     ]
    }
   ],
   "source": [
    "from estatisticas import porcent, moda\n",
    "moda(predict) #Just to test with predict, adjust to use with each candidate\n",
    "porcent(predict, \"Positivo\") \n",
    "porcent(predict, \"Neutro\") \n",
    "porcent(predict, \"Negativo\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
